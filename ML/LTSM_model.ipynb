{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  # type: ignore\n",
    "from tensorflow.keras.layers import Dense,LSTM,Dropout # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 11 #Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"H:/Projects/CryptoBot/btcusd_1-min_data.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "data['Timestamp'] =pd.to_datetime(data['Timestamp'],unit = 's')\n",
    "data = data.sort_values(by = \"Timestamp\")\n",
    "data['Timestamp']= data['Timestamp'].fillna(data[\"Timestamp\"].median())\n",
    "\n",
    "data = data[data['Timestamp'] >= data['Timestamp'].max() - timedelta(days=365*sample_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_features = [\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]\n",
    "data[\"target\"] = data[\"Close\"].shift(-1)\n",
    "\n",
    "\n",
    "\n",
    "dat =data.copy()\n",
    "\n",
    "for lag in range(1, 5):\n",
    "    for feature in lag_features:\n",
    "        data.loc[:, f\"{feature}_lag_{lag}\"] = data[feature].shift(lag)\n",
    "\n",
    "\n",
    "data['rolling_mean_5'] = data['Close'].rolling(window=5).mean()\n",
    "data['rolling_std_5'] = data['Close'].rolling(window=5).std()\n",
    "data['rolling_mean_10'] = data['Close'].rolling(window=10).mean()\n",
    "data['rolling_std_10'] = data['Close'].rolling(window=10).std()\n",
    "data['hour'] = data['Timestamp'].dt.hour\n",
    "data['day_of_week'] = data['Timestamp'].dt.dayofweek\n",
    "data['price_range'] = data['High'] - data['Low']\n",
    "\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Define the features and target\n",
    "features = [\n",
    "    \"Open\", \"High\", \"Low\", \"Close\", \"Volume\",\n",
    "    \"rolling_mean_5\", \"rolling_std_5\", \"rolling_mean_10\", \"rolling_std_10\",\n",
    "    \"hour\", \"day_of_week\"\n",
    "]\n",
    "target = \"Close\"\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[features + [target]])\n",
    "\n",
    "# Convert scaled data back to a DataFrame for easy manipulation\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=features + [target])\n",
    "scaled_data = scaled_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of timesteps to look back\n",
    "look_back = 10 # For example, use the last 60 timesteps to predict the next one\n",
    "\n",
    "# Create sequences\n",
    "X, y = [],[]\n",
    "for i in range(look_back, len(scaled_data)):\n",
    "    X.append(scaled_data[features].iloc[i-look_back:i].values)  # Features over the last 'look_back' timesteps\n",
    "    y.append(scaled_data[target].iloc[i])  # Target value at timestep i\n",
    "\n",
    "X, y = pd.array(X), pd.array(y)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(f\"X shape: {X.shape}\")  # Should be (samples, look_back, features)\n",
    "print(f\"y shape: {y.shape}\")  # Should be (samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# First LSTM layer with Dropout\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense output layer\n",
    "model.add(Dense(units=1))  # Single output (predicting 'Close')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse scale the predictions and actual values\n",
    "y_test_actual = scaler.inverse_transform(np.concatenate([np.zeros((len(y_test), len(features))), y_test.reshape(-1, 1)], axis=1))[:, -1]\n",
    "y_pred_actual = scaler.inverse_transform(np.concatenate([np.zeros((len(y_pred), len(features))), y_pred], axis=1))[:, -1]\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_actual, label=\"Actual\", color=\"blue\")\n",
    "plt.plot(y_pred_actual, label=\"Predicted\", color=\"orange\")\n",
    "plt.title(\"LSTM: Actual vs Predicted Closing Prices\")\n",
    "plt.xlabel(\"Time (Test Samples)\")\n",
    "plt.ylabel(\"Closing Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
